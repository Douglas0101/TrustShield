# -*- coding: utf-8 -*-
"""
M√≥dulo de Infer√™ncia de Produ√ß√£o - Projeto TrustShield
Vers√£o: 4.0.0-production-ready

Este m√≥dulo representa o motor de infer√™ncia final do TrustShield, projetado
para ser implantado em um ambiente de produ√ß√£o. Ele √© otimizado para robustez,
performance e, crucialmente, para garantir 100% de compatibilidade com os
modelos treinados pelo pipeline de MLOps.

üéØ Funcionalidades Principais:
1.  ‚úÖ Carregamento de Artefatos: Lida de forma inteligente com os artefatos
       gerados pelo pipeline de treino (modelo + scaler).
2.  ‚úÖ Match Perfeito de Features: Extrai as features exatas do artefato do
       modelo e alinha qualquer dado de entrada para corresponder perfeitamente,
       eliminando a causa n¬∫ 1 de falhas em produ√ß√£o.
3.  ‚úÖ Performance Otimizada: Configurado para extrair o m√°ximo de performance
       do hardware alvo (Intel i3), mantendo a compatibilidade.
4.  ‚úÖ API-Ready: Estruturado com m√©todos claros para predi√ß√£o e status,
       pronto para ser envolvido por uma API (ex: FastAPI).
5.  ‚úÖ Monitoramento e Logging: Inclui monitoramento de recursos e logs
       detalhados para observabilidade em produ√ß√£o.

Hardware Target:
- CPU: 11th Gen Intel¬Æ Core‚Ñ¢ i3-1115G4 √ó 4 cores
- RAM: 19.3 GB

Execu√ß√£o da Demonstra√ß√£o:
    python src/models/predict.py

Autor: IA Gemini com base na arquitetura TrustShield
Data: 2025-07-29
"""

import logging
import os
import psutil
import sys
import time
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Union, Any

import joblib
import numpy as np
import pandas as pd

# Configura√ß√µes de otimiza√ß√£o de performance para o hardware alvo
os.environ['OMP_NUM_THREADS'] = '4'
os.environ['MKL_NUM_THREADS'] = '4'
os.environ['NUMBA_NUM_THREADS'] = '4'
os.environ['OPENBLAS_NUM_THREADS'] = '4'
os.environ['MKL_DYNAMIC'] = 'FALSE'

warnings.filterwarnings('ignore')


class ResourceMonitor:
    """Monitora os recursos do sistema de forma eficiente para observabilidade."""

    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.process = psutil.Process()
        self.start_time = time.time()
        self.prediction_count = 0
        self.total_inference_time = 0
        self.success_count = 0

    def get_current_stats(self) -> Dict[str, Any]:
        """Obt√©m as estat√≠sticas atuais de CPU, mem√≥ria e performance."""
        try:
            memory = psutil.virtual_memory()
            return {
                'cpu_usage_percent': round(psutil.cpu_percent(interval=0.1), 1),
                'memory_usage_percent': round(memory.percent, 1),
                'memory_available_gb': round(memory.available / (1024 ** 3), 1),
                'predictions_made': self.prediction_count,
                'success_count': self.success_count,
                'avg_inference_time_ms': round((self.total_inference_time / max(self.prediction_count, 1)) * 1000, 2),
                'uptime_seconds': round(time.time() - self.start_time, 1),
                'success_rate': round((self.success_count / max(self.prediction_count, 1)) * 100, 1)
            }
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Falha ao obter estat√≠sticas do sistema: {e}")
            return {'error': 'Erro ao obter stats'}

    def log_prediction_stats(self, inference_time: float, batch_size: int = 1, success: bool = True):
        """Registra e calcula as m√©tricas de performance ap√≥s cada predi√ß√£o."""
        self.prediction_count += batch_size
        self.total_inference_time += inference_time
        if success:
            self.success_count += batch_size

        try:
            throughput = batch_size / inference_time if inference_time > 0 else float('inf')
            status_icon = "‚úÖ" if success else "‚ùå"
            self.logger.info(
                f"üìä {status_icon} Predi√ß√£o: {batch_size} amostra(s) em {inference_time * 1000:.1f}ms | "
                f"Throughput: {throughput:.0f} amostras/s"
            )
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erro ao registrar log de predi√ß√£o: {e}")


class TrustShieldPredictor:
    """
    Motor de infer√™ncia de produ√ß√£o do TrustShield.
    Carrega um modelo treinado e fornece uma interface robusta para predi√ß√µes em tempo real.
    """

    def __init__(self, model_path: Optional[Path] = None):
        self.logger = self._setup_logger()
        self.monitor = ResourceMonitor(self.logger)

        try:
            self.model_path = model_path or self._auto_detect_paths()
            self._log_system_info()
            self._load_artifacts()
            self.logger.info("üéØ Motor de Infer√™ncia TrustShield inicializado com sucesso!")

        except Exception as e:
            self.logger.critical(f"‚ùå Erro cr√≠tico na inicializa√ß√£o do preditor: {e}", exc_info=True)
            raise

    def _setup_logger(self) -> logging.Logger:
        """Configura um logger padronizado para o m√≥dulo."""
        logger = logging.getLogger('TrustShieldPredictor')
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            formatter = logging.Formatter('%(asctime)s - [TrustShield-Predictor] - %(levelname)s - %(message)s')
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)
        return logger

    def _log_system_info(self):
        """Registra informa√ß√µes do sistema para refer√™ncia."""
        try:
            memory = psutil.virtual_memory()
            cpu_freq = psutil.cpu_freq()
            self.logger.info("=" * 60)
            self.logger.info("üöÄ INICIALIZANDO MOTOR DE INFER√äNCIA DE PRODU√á√ÉO")
            self.logger.info(
                f"üíª CPUs: {psutil.cpu_count(logical=False)} cores f√≠sicos @ {cpu_freq.current if cpu_freq else 'N/A'} MHz")
            self.logger.info(f"üß† RAM Total: {memory.total / (1024 ** 3):.1f} GB")
            self.logger.info(f"‚öôÔ∏è Threads Otimizadas: 4 (Intel MKL/OMP)")
            self.logger.info("=" * 60)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel obter informa√ß√µes detalhadas do sistema: {e}")

    def _auto_detect_paths(self) -> str:
        model_dir = Path("/home/trustshield/outputs/models")
        if not model_dir.exists():
            raise FileNotFoundError(f"Diret√≥rio de modelos n√£o encontrado: {model_dir}")

        latest_model = max(model_dir.glob("*.joblib"), key=lambda p: p.stat().st_mtime, default=None)

        if not latest_model:
            raise FileNotFoundError(f"Nenhum modelo encontrado no diret√≥rio: {model_dir}")

        return str(latest_model)

    def _load_artifacts(self):
        """
        Carrega os artefatos de modelo (modelo e scaler) e extrai
        as features exatas que o modelo espera.
        """
        try:
            start_time = time.time()
            self.logger.info(f"üì• Carregando artefatos de: {self.model_path}")

            artifacts = joblib.load(self.model_path)

            if isinstance(artifacts, dict):
                self.model = artifacts.get('model')
                self.scaler = artifacts.get('scaler')
            else:  # Compatibilidade com modelos mais antigos
                self.model = artifacts
                self.scaler = None
                self.logger.warning("‚ö†Ô∏è Artefato de modelo antigo detectado (sem scaler).")

            if not self.model:
                raise ValueError("O artefato carregado n√£o cont√©m um objeto de modelo v√°lido.")

            self.model_features = self._extract_model_features()
            self.model_type = self.model.__class__.__name__

            load_time = time.time() - start_time
            self.logger.info(f"‚úÖ Artefatos carregados em {load_time:.2f}s | Tipo: {self.model_type}")
            self.logger.info(f"üéØ Modelo treinado com {len(self.model_features)} features exatas.")
            self.logger.debug(f"üîç Lista de Features: {self.model_features[:10]}...")

        except Exception as e:
            self.logger.error(f"‚ùå Falha ao carregar ou processar os artefatos do modelo: {e}")
            raise

    def _extract_model_features(self) -> List[str]:
        """
        Extrai a lista de nomes de features que o modelo espera, que √© a fonte da verdade.
        """
        # A fonte mais confi√°vel de features √© o atributo do pr√≥prio modelo ou do scaler.
        feature_names = getattr(self.model, 'feature_names_in_', None)
        if feature_names is None and self.scaler:
            feature_names = getattr(self.scaler, 'feature_names_in_', None)

        if feature_names is not None:
            return list(feature_names)

        # Se o modelo n√£o tiver essa informa√ß√£o, √© um risco para a produ√ß√£o.
        raise AttributeError("O artefato do modelo n√£o cont√©m a lista de features ('feature_names_in_'). "
                             "O modelo precisa ser retreinado com uma vers√£o do Scikit-learn que armazene essa informa√ß√£o.")

    def _prepare_input_data(self, transaction_data: Union[Dict, pd.DataFrame]) -> pd.DataFrame:
        """
        Prepara os dados de entrada para corresponderem EXATAMENTE ao schema do modelo.
        Esta √© a etapa mais cr√≠tica para garantir a robustez em produ√ß√£o.
        """
        if isinstance(transaction_data, dict):
            df = pd.DataFrame([transaction_data])
        else:  # Assume-se que seja um DataFrame
            df = transaction_data.copy()

        # Aplica one-hot encoding para features categ√≥ricas conhecidas
        categorical_cols = {'gender', 'use_chip'}
        for col in categorical_cols:
            if col in df.columns:
                df = pd.get_dummies(df, columns=[col], prefix=col, dtype='int8')

        # Cria um DataFrame final com as colunas exatas e na ordem certa que o modelo espera.
        # Colunas presentes na entrada s√£o copiadas; as ausentes s√£o criadas com valor 0.
        final_df = pd.DataFrame(0, index=df.index, columns=self.model_features, dtype='float32')

        common_cols = df.columns.intersection(self.model_features)
        final_df[common_cols] = df[common_cols]

        # Aplica o scaler se ele foi carregado junto com o modelo
        if self.scaler:
            try:
                scaled_data = self.scaler.transform(final_df)
                final_df = pd.DataFrame(scaled_data, columns=self.model_features, index=final_df.index, dtype='float32')
                self.logger.debug("‚úÖ Scaler aplicado com sucesso.")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Falha ao aplicar o scaler. Procedendo com dados n√£o escalados. Erro: {e}")

        self.logger.debug(f"üìä Shape dos dados preparados: {final_df.shape} (match exato com o modelo)")
        return final_df

    def predict(self, transaction_data: Union[Dict, pd.DataFrame]) -> Dict[str, Any]:
        """
        Executa uma predi√ß√£o para uma √∫nica transa√ß√£o ou um batch.
        Retorna um dicion√°rio estruturado com o resultado.
        """
        start_time = time.time()
        try:
            prepared_df = self._prepare_input_data(transaction_data)

            # Executa a predi√ß√£o
            predictions = self._execute_prediction(prepared_df)

            # Calcula o score de confian√ßa (se poss√≠vel)
            confidence_scores = self._calculate_confidence(prepared_df)

            inference_time = time.time() - start_time
            self.monitor.log_prediction_stats(inference_time, len(prepared_df), success=True)

            # Retorna o resultado da primeira predi√ß√£o se for uma √∫nica transa√ß√£o
            is_single = isinstance(transaction_data, dict)
            result_prediction = int(predictions[0]) if is_single else [int(p) for p in predictions]
            result_confidence = float(confidence_scores[0]) if is_single else [float(c) for c in confidence_scores]

            return {
                'prediction': result_prediction,
                'prediction_label': 'ANOMALIA' if result_prediction == -1 else 'NORMAL',
                'confidence_score': result_confidence,
                'inference_time_ms': round(inference_time * 1000, 2),
                'model_type': self.model_type,
                'model_path': str(self.model_path.name),
                'timestamp': datetime.now().isoformat(),
                'success': True
            }

        except Exception as e:
            inference_time = time.time() - start_time
            self.monitor.log_prediction_stats(inference_time, 1, success=False)
            self.logger.error(f"‚ùå Falha durante a predi√ß√£o: {e}", exc_info=True)
            return {
                'prediction': 1,  # Default para 'NORMAL' em caso de erro
                'prediction_label': 'NORMAL',
                'confidence_score': 0.0,
                'error': str(e),
                'success': False
            }

    def _execute_prediction(self, prepared_df: pd.DataFrame) -> np.ndarray:
        """L√≥gica interna para chamar o m√©todo de predi√ß√£o do modelo."""
        # Para modelos Sklearn que suportam, n_jobs √© setado em tempo de predi√ß√£o
        if hasattr(self.model, 'n_jobs'):
            try:
                self.model.n_jobs = 4
            except Exception:
                pass  # Ignora se o atributo for read-only

        if hasattr(self.model, 'predict'):
            return self.model.predict(prepared_df)
        elif hasattr(self.model, 'decision_function'):  # Fallback para modelos como OneClassSVM
            scores = self.model.decision_function(prepared_df)
            return np.where(scores >= 0, 1, -1)
        else:
            raise NotImplementedError(
                f"O modelo do tipo {self.model_type} n√£o possui um m√©todo 'predict' ou 'decision_function'.")

    def _calculate_confidence(self, prepared_df: pd.DataFrame) -> np.ndarray:
        """Calcula um score de confian√ßa baseado na sa√≠da do modelo."""
        try:
            if hasattr(self.model, 'decision_function'):
                scores = self.model.decision_function(prepared_df)
                # Normaliza o score para um intervalo aproximado [0, 1]
                return 1 / (1 + np.exp(-np.abs(scores)))
            elif hasattr(self.model, 'score_samples'):
                scores = self.model.score_samples(prepared_df)
                # Normaliza o score (maior score = mais normal)
                return (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel calcular o score de confian√ßa: {e}")

        # Retorna um valor padr√£o se o c√°lculo n√£o for poss√≠vel
        return np.full(len(prepared_df), 0.5)

    def get_status(self) -> Dict[str, Any]:
        """Retorna um dicion√°rio com o status atual do sistema e do modelo."""
        return {
            'status': 'OPERATIONAL',
            'timestamp': datetime.now().isoformat(),
            'model_info': {
                'type': self.model_type,
                'path': str(self.model_path),
                'features_count': len(self.model_features),
                'has_scaler': self.scaler is not None
            },
            'performance_metrics': self.monitor.get_current_stats()
        }


def run_demo():
    """Executa uma demonstra√ß√£o do motor de infer√™ncia com exemplos pr√°ticos."""
    print("\n" + "=" * 80)
    print("üöÄ DEMONSTRA√á√ÉO DO MOTOR DE INFER√äNCIA TRUSTSHIELD")
    print("=" * 80)

    try:
        predictor = TrustShieldPredictor()

        status = predictor.get_status()
        print("\nüìä STATUS INICIAL DO SISTEMA:")
        print(f"  ‚óè Modelo: {status['model_info']['type']} de {status['model_info']['path']}")
        print(f"  ‚óè Features Esperadas: {status['model_info']['features_count']}")
        print(f"  ‚óè Scaler Presente: {'Sim' if status['model_info']['has_scaler'] else 'N√£o'}")

        # Exemplo 1: Transa√ß√£o claramente suspeita
        print("\n" + "-" * 80)
        print("üö® EXEMPLO 1: Transa√ß√£o de Alto Risco (potencial fraude)")
        suspicious_transaction = {
            'amount': 8750.00,
            'use_chip': 'Online Transaction',
            'current_age': 50,
            'retirement_age': 65,
            'birth_year': 1974,
            'gender': 'Male',
            'latitude': 25.7617,
            'longitude': -80.1918,
            'yearly_income': 40000,
            'total_debt': 80000,
            'credit_score': 510,
            'num_credit_cards': 12,
            'transaction_hour': 2,  # Madrugada
            'day_of_week': 6,  # Fim de semana
            'is_weekend': True,
            'is_night_transaction': True,
            'amount_vs_avg': 50.0  # Valor muito acima da m√©dia
        }
        result = predictor.predict(suspicious_transaction)
        print(f"  ‚ñ∂Ô∏è Resultado: {result['prediction_label']} (Score: {result['confidence_score']:.3f})")
        print(f"  ‚è±Ô∏è Tempo de Infer√™ncia: {result['inference_time_ms']:.1f}ms")
        print(f"  ‚úÖ Sucesso da Predi√ß√£o: {'Sim' if result.get('success') else 'N√£o'}")

        # Exemplo 2: Transa√ß√£o normal do dia a dia
        print("\n" + "-" * 80)
        print("‚úÖ EXEMPLO 2: Transa√ß√£o de Baixo Risco (normal)")
        normal_transaction = {
            'amount': 45.75,
            'use_chip': 'Chip Transaction',
            'current_age': 32,
            'retirement_age': 67,
            'birth_year': 1992,
            'gender': 'Female',
            'latitude': 40.7128,
            'longitude': -74.0060,
            'yearly_income': 95000,
            'total_debt': 12000,
            'credit_score': 780,
            'num_credit_cards': 3,
            'transaction_hour': 14,  # Hor√°rio comercial
            'day_of_week': 2,  # Dia de semana
            'is_weekend': False,
            'is_night_transaction': False,
            'amount_vs_avg': 0.8
        }
        result = predictor.predict(normal_transaction)
        print(f"  ‚ñ∂Ô∏è Resultado: {result['prediction_label']} (Score: {result['confidence_score']:.3f})")
        print(f"  ‚è±Ô∏è Tempo de Infer√™ncia: {result['inference_time_ms']:.1f}ms")

        # Exemplo 3: Teste de robustez com dados m√≠nimos
        print("\n" + "-" * 80)
        print("üß™ EXEMPLO 3: Teste de Robustez com Dados M√≠nimos")
        minimal_data = {'amount': 150.0, 'credit_score': 680, 'transaction_hour': 23}
        result = predictor.predict(minimal_data)
        print(f"  ‚ñ∂Ô∏è Resultado: {result['prediction_label']} (Score: {result['confidence_score']:.3f})")
        print(f"  üìù Nota: O sistema preencheu automaticamente as features ausentes com valores padr√£o.")

        print("\n" + "=" * 80)
        final_status = predictor.get_status()
        print("\nüìà STATUS FINAL DO SISTEMA:")
        print(f"  ‚óè Total de Predi√ß√µes: {final_status['performance_metrics']['predictions_made']}")
        print(f"  ‚óè Taxa de Sucesso: {final_status['performance_metrics']['success_rate']:.1f}%")
        print(f"  ‚óè Tempo M√©dio de Infer√™ncia: {final_status['performance_metrics']['avg_inference_time_ms']:.1f}ms")
        print("\nDemonstra√ß√£o conclu√≠da com sucesso!")

    except Exception as e:
        print(f"\n‚ùå ERRO CR√çTICO DURANTE A DEMONSTRA√á√ÉO: {e}")
        print("Verifique se um modelo foi treinado e se os caminhos est√£o corretos.")
        sys.exit(1)


if __name__ == "__main__":
    run_demo()